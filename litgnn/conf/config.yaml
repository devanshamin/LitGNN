defaults:
  - _self_
  - dataset: ???
  - model: ???
  - task: ???
  - override hydra/job_logging: custom

model:
  _target_: litgnn.models.graph_level.GraphLevelGNN
  pooling_func_name: global_mean_pool

train:
  num_seed_runs: 5  # No. of times to run the train-test split with different seeds
  seed: 1
  dataset: 
    split: scaffold_split
    split_sizes: [0.8, 0.1, 0.1]
    num_node_features: ???
    num_edge_features: ???
  batch_size: 32
  epochs: 100
  early_stopping: 10
  scheduler:
    _target_: litgnn.utils.NoamLR
    warmup_epochs: [2]
    total_epochs: 
      - ${train.epochs}
    init_lr: [1e-4]
    max_lr: [1e-3]
    final_lr: [1e-4]
  optimizer:
    _target_: torch.optim.Adam
    lr: ${train.scheduler.init_lr[0]}
    weight_decay: 0
